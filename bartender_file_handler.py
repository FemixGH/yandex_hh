# bartender_file_handler.py - –û–±—Ä–∞–±–æ—Ç—á–∏–∫ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –ò–ò –ë–∞—Ä–º–µ–Ω–∞
import os
import csv
import json
import logging
import pandas as pd
from typing import List, Dict, Optional
import boto3
import fitz
from settings import S3_ENDPOINT, S3_ACCESS_KEY, S3_SECRET_KEY

logger = logging.getLogger(__name__)

def download_file_bytes(bucket: str, key: str, endpoint: str = S3_ENDPOINT,
                       access_key: Optional[str] = None, secret_key: Optional[str] = None) -> bytes:
    """–°–∫–∞—á–∏–≤–∞–µ—Ç —Ñ–∞–π–ª –∏–∑ S3 –±–∞–∫–µ—Ç–∞"""
    access_key = access_key or S3_ACCESS_KEY
    secret_key = secret_key or S3_SECRET_KEY
    s3 = boto3.client(
        "s3",
        endpoint_url=endpoint,
        aws_access_key_id=access_key,
        aws_secret_access_key=secret_key,
    )
    resp = s3.get_object(Bucket=bucket, Key=key)
    return resp["Body"].read()

def extract_text_from_pdf_bytes(pdf_bytes: bytes) -> str:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏–∑ PDF"""
    doc = fitz.Document(stream=pdf_bytes, filetype="pdf")
    pages = []
    for page in doc:
        pages.append(page.get_text())
    doc.close()
    return "\n".join(pages)

def extract_text_from_csv_bytes(csv_bytes: bytes, encoding: str = 'utf-8') -> str:
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏–∑ CSV —Ñ–∞–π–ª–∞, –ø—Ä–µ–æ–±—Ä–∞–∑—É—è –µ–≥–æ –≤ —á–∏—Ç–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–ª—è –±–∞—Ä–º–µ–Ω—Å–∫–æ–≥–æ –ò–ò
    """
    try:
        # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –∫–æ–¥–∏—Ä–æ–≤–∫–∏
        for enc in [encoding, 'utf-8', 'cp1251', 'windows-1251', 'latin-1']:
            try:
                csv_text = csv_bytes.decode(enc)
                break
            except UnicodeDecodeError:
                continue
        else:
            raise UnicodeDecodeError("–ù–µ —É–¥–∞–ª–æ—Å—å –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞—Ç—å CSV —Ñ–∞–π–ª")

        # –ü–∞—Ä—Å–∏–º CSV
        import io
        csv_file = io.StringIO(csv_text)
        reader = csv.DictReader(csv_file)

        extracted_text = []

        # –î–æ–±–∞–≤–ª—è–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
        if reader.fieldnames:
            extracted_text.append(f"üç∏ –ë–∞—Ä–Ω–∞—è –±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö - —Å—Ç—Ä—É–∫—Ç—É—Ä–∞: {', '.join(reader.fieldnames)}")
            extracted_text.append("=" * 60)

        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å—Ç—Ä–æ–∫–∏
        for i, row in enumerate(reader):
            if i >= 1000:  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫
                extracted_text.append(f"... –∏ –µ—â–µ {sum(1 for _ in reader) + 1} –∑–∞–ø–∏—Å–µ–π –≤ –±–∞—Ä–Ω–æ–π –∫–∞—Ä—Ç–µ")
                break

            # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Å—Ç—Ä–æ–∫—É –≤ –±–∞—Ä–Ω—ã–π —Å—Ç–∏–ª—å
            row_text = []
            for field, value in row.items():
                if value and str(value).strip():
                    # –°–ø–µ—Ü–∏–∞–ª—å–Ω–æ–µ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –±–∞—Ä–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
                    if any(keyword in field.lower() for keyword in ['–Ω–∞–∑–≤–∞–Ω–∏–µ', 'name', 'cocktail', '–∫–æ–∫—Ç–µ–π–ª—å']):
                        row_text.append(f"üçπ {field}: {value}")
                    elif any(keyword in field.lower() for keyword in ['–∏–Ω–≥—Ä–µ–¥–∏–µ–Ω—Ç', 'ingredient', '—Å–æ—Å—Ç–∞–≤']):
                        row_text.append(f"ü•É {field}: {value}")
                    elif any(keyword in field.lower() for keyword in ['—Ä–µ—Ü–µ–ø—Ç', 'recipe', '–ø—Ä–∏–≥–æ—Ç–æ–≤–ª–µ–Ω–∏–µ']):
                        row_text.append(f"üìù {field}: {value}")
                    elif any(keyword in field.lower() for keyword in ['–∞–ª–∫–æ–≥–æ–ª—å', 'alcohol', '–≥—Ä–∞–¥—É—Å', '–∫—Ä–µ–ø–æ—Å—Ç—å']):
                        row_text.append(f"üî• {field}: {value}")
                    else:
                        row_text.append(f"{field}: {value}")

            if row_text:
                extracted_text.append(f"–ü–æ–∑–∏—Ü–∏—è {i+1}: " + " | ".join(row_text))

        return "\n".join(extracted_text)

    except Exception as e:
        logger.exception("–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ CSV: %s", e)
        # Fallback - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –ø—Ä–æ—Å—Ç–æ–π —Ç–µ–∫—Å—Ç
        try:
            return csv_bytes.decode('utf-8', errors='ignore')
        except:
            return csv_bytes.decode('latin-1', errors='ignore')

def extract_text_from_txt_bytes(txt_bytes: bytes, encoding: str = 'utf-8') -> str:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏–∑ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ —Ñ–∞–π–ª–∞"""
    for enc in [encoding, 'utf-8', 'cp1251', 'windows-1251', 'latin-1']:
        try:
            return txt_bytes.decode(enc)
        except UnicodeDecodeError:
            continue
    return txt_bytes.decode('latin-1', errors='ignore')

def extract_text_from_json_bytes(json_bytes: bytes, encoding: str = 'utf-8') -> str:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏–∑ JSON —Ñ–∞–π–ª–∞ —Å –±–∞—Ä–Ω—ã–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º"""
    try:
        json_text = json_bytes.decode(encoding)
        data = json.loads(json_text)

        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º JSON –≤ —á–∏—Ç–∞–µ–º—ã–π —Ç–µ–∫—Å—Ç —Å –±–∞—Ä–Ω—ã–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º
        def json_to_bartender_text(obj, indent=0):
            if isinstance(obj, dict):
                lines = []
                for key, value in obj.items():
                    if isinstance(value, (dict, list)):
                        # –î–æ–±–∞–≤–ª—è–µ–º —ç–º–æ–¥–∑–∏ –¥–ª—è –±–∞—Ä–Ω—ã—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤
                        if any(keyword in key.lower() for keyword in ['cocktail', '–∫–æ–∫—Ç–µ–π–ª—å', 'drink']):
                            lines.append("  " * indent + f"üçπ {key}:")
                        elif any(keyword in key.lower() for keyword in ['ingredient', '–∏–Ω–≥—Ä–µ–¥–∏–µ–Ω—Ç']):
                            lines.append("  " * indent + f"ü•É {key}:")
                        else:
                            lines.append("  " * indent + f"{key}:")
                        lines.append(json_to_bartender_text(value, indent + 1))
                    else:
                        lines.append("  " * indent + f"{key}: {value}")
                return "\n".join(lines)
            elif isinstance(obj, list):
                lines = []
                for i, item in enumerate(obj[:100]):  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–æ 100 —ç–ª–µ–º–µ–Ω—Ç–æ–≤
                    if isinstance(item, (dict, list)):
                        lines.append("  " * indent + f"–ü–æ–∑–∏—Ü–∏—è {i+1}:")
                        lines.append(json_to_bartender_text(item, indent + 1))
                    else:
                        lines.append("  " * indent + f"–ü–æ–∑–∏—Ü–∏—è {i+1}: {item}")
                if len(obj) > 100:
                    lines.append("  " * indent + f"... –∏ –µ—â–µ {len(obj) - 100} –ø–æ–∑–∏—Ü–∏–π –≤ –±–∞—Ä–Ω–æ–π –∫–∞—Ä—Ç–µ")
                return "\n".join(lines)
            else:
                return str(obj)

        return "üç∏ –ë–∞—Ä–Ω–∞—è –±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö (JSON):\n" + json_to_bartender_text(data)

    except Exception as e:
        logger.exception("–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ JSON: %s", e)
        return json_bytes.decode('utf-8', errors='ignore')

def extract_text_from_file(file_bytes: bytes, filename: str) -> str:
    """
    –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –∏–∑ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ç–∏–ø–æ–≤ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –±–∞—Ä–º–µ–Ω–∞
    """
    filename_lower = filename.lower()

    if filename_lower.endswith('.pdf'):
        return extract_text_from_pdf_bytes(file_bytes)
    elif filename_lower.endswith('.csv'):
        return extract_text_from_csv_bytes(file_bytes)
    elif filename_lower.endswith(('.txt', '.md', '.rst')):
        return extract_text_from_txt_bytes(file_bytes)
    elif filename_lower.endswith('.json'):
        return extract_text_from_json_bytes(file_bytes)
    else:
        # –ü—Ä–æ–±—É–µ–º –∫–∞–∫ —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª
        logger.warning("–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∏–ø —Ñ–∞–π–ª–∞ %s, –ø—Ä–æ–±—É–µ–º –∫–∞–∫ —Ç–µ–∫—Å—Ç", filename)
        return extract_text_from_txt_bytes(file_bytes)

def chunk_text(text: str, max_chars: int = 1500) -> List[str]:
    """
    –†–∞–∑–±–∏–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç –Ω–∞ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã —Å —É—á–µ—Ç–æ–º –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π API Yandex
    """
    if not text:
        return []
    text = text.strip()
    if len(text) <= max_chars:
        return [text]

    chunks = []
    start = 0
    L = len(text)

    while start < L:
        end = min(start + max_chars, L)
        if end < L:
            # –ò—â–µ–º —Ä–∞–∑—Ä—ã–≤ —Å—Ç—Ä–æ–∫–∏
            cut_pos = text.rfind('\n', start, end)
            if cut_pos <= start:
                # –ò—â–µ–º –ø—Ä–æ–±–µ–ª
                cut_pos = text.rfind(' ', start, end)
            if cut_pos <= start:
                # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏, —Ä–µ–∂–µ–º –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ
                cut_pos = end
        else:
            cut_pos = end

        chunk = text[start:cut_pos].strip()
        if chunk:
            chunks.append(chunk)

        if cut_pos <= start:
            start = end
        else:
            start = cut_pos

    return chunks

def build_bartender_index_from_bucket(bucket: str, prefix: str = "", embedding_model_uri: Optional[str] = None,
                                    max_chunk_chars: Optional[int] = None):
    """
    –†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –∏–Ω–¥–µ–∫—Å–∞ –¥–ª—è –±–∞—Ä–º–µ–Ω–∞, –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—â–∞—è –º–Ω–æ–∂–µ—Å—Ç–≤–æ —Ñ–æ—Ä–º–∞—Ç–æ–≤ —Ñ–∞–π–ª–æ–≤
    """
    if max_chunk_chars is None:
        try:
            max_chunk_chars = int(os.getenv("YAND_MAX_CHUNK_CHARS", "1500"))
        except Exception:
            max_chunk_chars = 1500

    access_key = S3_ACCESS_KEY
    secret_key = S3_SECRET_KEY
    if not access_key or not secret_key:
        logger.error("S3 access key / secret key not set")
        return

    s3 = boto3.client(
        "s3",
        endpoint_url=S3_ENDPOINT,
        aws_access_key_id=access_key,
        aws_secret_access_key=secret_key,
    )

    try:
        response = s3.list_objects_v2(Bucket=bucket, Prefix=prefix)
    except Exception as e:
        logger.exception("–û—à–∏–±–∫–∞ –¥–æ—Å—Ç—É–ø–∞ –∫ S3: %s", e)
        return

    contents = response.get("Contents") or []
    if not contents:
        logger.warning("–í –±–∞–∫–µ—Ç–µ %s —Å –ø—Ä–µ—Ñ–∏–∫—Å–æ–º '%s' –Ω–µ—Ç —Ñ–∞–π–ª–æ–≤", bucket, prefix)
        return

    docs_for_index = []
    supported_extensions = ['.pdf', '.csv', '.txt', '.md', '.json', '.rst']

    for obj in contents:
        key = obj.get("Key")
        if not key:
            continue

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è
        if not any(key.lower().endswith(ext) for ext in supported_extensions):
            logger.info("–ü—Ä–æ–ø—É—Å–∫–∞–µ–º –Ω–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–∞–π–ª: %s", key)
            continue

        try:
            file_bytes = download_file_bytes(bucket, key, endpoint=S3_ENDPOINT,
                                           access_key=access_key, secret_key=secret_key)
            text = extract_text_from_file(file_bytes, key)

            # –û—á–∏—Å—Ç–∫–∞ –∏ —Ä–∞–∑–±–∏–≤–∫–∞
            text_clean = " ".join(text.split())
            chunks = chunk_text(text_clean, max_chars=max_chunk_chars)

            for i, ch in enumerate(chunks):
                part_id = f"{os.path.basename(key)}__part{i+1}"
                docs_for_index.append({
                    "id": part_id,
                    "text": ch,
                    "meta": {
                        "source": key,
                        "part": i+1,
                        "file_type": os.path.splitext(key)[1].lower()
                    }
                })

            logger.info("üç∏ –û–±—Ä–∞–±–æ—Ç–∞–Ω —Ñ–∞–π–ª %s -> %d —á–∞—Å—Ç–µ–π –≤ –±–∞—Ä–Ω—É—é –±–∞–∑—É", key, len(chunks))

        except Exception as e:
            logger.exception("–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞ %s: %s", key, e)

    if docs_for_index:
        # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Ñ—É–Ω–∫—Ü–∏—é –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞
        from rag_yandex_nofaiss import build_vectorstore_from_docs
        build_vectorstore_from_docs(docs_for_index, embedding_model_uri=embedding_model_uri)
        logger.info("üç∏ –ë–∞—Ä–Ω–∞—è –±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –ø–æ—Å—Ç—Ä–æ–µ–Ω–∞: %d –ø–æ–∑–∏—Ü–∏–π –∏–∑ %d —Ñ–∞–π–ª–æ–≤",
                   len(docs_for_index), len([obj for obj in contents
                   if any(obj.get("Key", "").lower().endswith(ext) for ext in supported_extensions)]))
    else:
        logger.warning("–ù–µ –Ω–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –±–∞—Ä–Ω–æ–π –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö")
